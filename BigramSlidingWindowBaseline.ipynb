{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THIS IS OUR BASELINE MODEL.  STRIPS OUT THE BIO TAGS, which is an enhancement.\n",
    "\n",
    "import operator\n",
    "import re\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "class ScienceNerBaseline():\n",
    "    \n",
    "    # load the training set, and insert 1 'unknown' tokens (and it's unknown tag) between each paragraph\n",
    "    def load(self,inFile) :\n",
    "        txtfile = open(inFile, \"r\")\n",
    "        self.tokens = []\n",
    "        for i in txtfile :\n",
    "            if i.strip() == \"\" :\n",
    "                self.tokens.append((\"<UNK>\", \"<UNK>\"))\n",
    "                continue\n",
    "            wd, tag = i.strip().split()\n",
    "            \n",
    "            # the raw text contains the B/I/O tags which we do not want to count in the baseline\n",
    "            if (tag == \"O\") :\n",
    "                tag_pred = \"\"\n",
    "            else :\n",
    "                m = re.match(\"(.*)-(.*)\", tag)\n",
    "                if m != None :\n",
    "                    tag_pred = m.group(2)\n",
    "            self.tokens.append((wd, tag_pred))\n",
    "        txtfile.close()\n",
    "        \n",
    "    \n",
    "    # this function slides a 2-word window over the entire training set word-by-word to\n",
    "    # get every bigram, and classifies the 2-gram to be whatever tag the current word is\n",
    "    def countBigrams(self):\n",
    "        self.counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "        self.context_totals = dict()\n",
    "        w_1 = None, None\n",
    "        for word in self.tokens:\n",
    "            \n",
    "            # word and tag\n",
    "            wd, tk = word\n",
    "            if w_1 is not None :\n",
    "                self.counts[(w_1,wd)][tk] += 1\n",
    "            w_1 = wd\n",
    "\n",
    "    \n",
    "    # this function run the test set and calculates accuracy\n",
    "    def evaluate(self, testfile) :   \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        txtfile = open(testfile, \"r\")\n",
    "        testtokens = []\n",
    "        for i in txtfile :\n",
    "            \n",
    "            # if there is a blank space in the test file, add 1 unknown token\n",
    "            if i.strip() == \"\" :\n",
    "                testtokens.append((\"<UNK>\", \"<UNK>\"))\n",
    "                continue\n",
    "            wd, tag = i.strip().split()\n",
    "            testtokens.append((wd, tag))\n",
    "        txtfile.close()\n",
    "        \n",
    "                \n",
    "        w_1 = None, None\n",
    "        num_correct = num_test = 0\n",
    "        for word in testtokens:\n",
    "            tag_true = \"\"\n",
    "            wd, tk = word\n",
    "\n",
    "            m = re.match(\"(.*)-(.*)\", tk)\n",
    "            if m != None :\n",
    "                tag_true = m.group(2)\n",
    "            \n",
    "            # skip unknown words and create 2 dummy trigram tokens for beginning\n",
    "            if w_1 is not None and wd is not \"<UNK>\":\n",
    "                # context is w_1, wd\n",
    "                if (w_1,wd) not in self.counts :\n",
    "                    prediction = [\"\"]\n",
    "                else :\n",
    "                    prediction = max(self.counts[(w_1,wd)].iteritems())\n",
    "                \n",
    "                # correct prediction\n",
    "                y_pred += [prediction[0]]\n",
    "                y_true += [tag_true]\n",
    "                    \n",
    "            w_1 = wd\n",
    "            \n",
    "            \n",
    "        # find the number of labeled predictions - for use in precision calculation\n",
    "        num_pos_predictions = len([pr for pr in y_pred if pr!=\"\"])\n",
    "        \n",
    "        # find number of true labels - for use in recall calculation\n",
    "        num_true_labels = len([pr for pr in y_true if pr!=\"\"])\n",
    "\n",
    "        num_correct = numcorrect_all = 0\n",
    "        for (a,b) in zip(y_pred,y_true) :\n",
    "            if (a == b) :\n",
    "                numcorrect_all+=1\n",
    "                if (a != \"\") :\n",
    "                    \n",
    "                    # get the number of cases correctly labeled\n",
    "                    num_correct+=1\n",
    "\n",
    "        precision = num_correct * 1.0 / num_pos_predictions\n",
    "        recall = num_correct * 1.0 / num_true_labels\n",
    "        accuracy = numcorrect_all * 1.0 / len(y_pred)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "\n",
    "        return (f1, precision, accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.717123433185\n",
      "F1 is : 0.0604770017036\n",
      "Precision is : 0.0518475244633\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "modelInst = ScienceNerBaseline()\n",
    "\n",
    "#os.chdir('..')\n",
    "#os.chdir('w266_project')\n",
    "#os.chdir('data')\n",
    "modelInst.load(\"train.txt\")\n",
    "modelInst.countBigrams()\n",
    "f1, precision, acc = modelInst.evaluate(\"test.txt\")\n",
    "print \"Accuracy is :\", acc\n",
    "print \"F1 is :\", f1\n",
    "print \"Precision is :\", precision\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
