{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Part-of-speech tagging with HMMs\n",
    "\n",
    "In this part of the assignment, we'll train a Hidden Markov Model (HMM) as a part-of-speech (POS) tagger, and implement both Forward-Backward inference and Viterbi decoding.\n",
    "\n",
    "We'll be doing this using the data provided as part of SemEval 2017 Task 10.\n",
    "\n",
    "In particular:\n",
    "- **(b)** Implement the Forward-Backward algorithm for marginal inference of $ P(y_i\\ |\\ x) $\n",
    "- **(c)** Implement the Viterbi algorithm to find the most likely tag _sequence_ $ \\hat{y} = \\arg\\max_{y'} P(y'\\ |\\ x) $\n",
    "\n",
    "\n",
    "\n",
    "## Inspect Data Provided as Part of SemEval 2017 Task 10\n",
    "Need to format incoming data to be processed by NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3914 sentences in the corpus.\n",
      "The first sentence is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'Pierre', u'NNP'),\n",
       " (u'Vinken', u'NNP'),\n",
       " (u',', u','),\n",
       " (u'61', u'CD'),\n",
       " (u'years', u'NNS'),\n",
       " (u'old', u'JJ'),\n",
       " (u',', u','),\n",
       " (u'will', u'MD'),\n",
       " (u'join', u'VB'),\n",
       " (u'the', u'DT'),\n",
       " (u'board', u'NN'),\n",
       " (u'as', u'IN'),\n",
       " (u'a', u'DT'),\n",
       " (u'nonexecutive', u'JJ'),\n",
       " (u'director', u'NN'),\n",
       " (u'Nov.', u'NNP'),\n",
       " (u'29', u'CD'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "import pos\n",
    "import pos_test\n",
    "import nltk\n",
    "\n",
    "# Load the Penn Treebank Corpus which will serve as our training set.\n",
    "corpus = nltk.corpus.treebank\n",
    "print 'There are %d sentences in the corpus.' % len(corpus.tagged_sents())\n",
    "print 'The first sentence is:'\n",
    "corpus.tagged_sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "corpus=[]\n",
    "current_sent=[]\n",
    "last_token=''\n",
    "err='none'\n",
    "with codecs.open(\"train.txt\", 'r', 'utf-8') as f:\n",
    "#with codecs.open(\"test.txt\", 'r', 'utf-8') as f:\n",
    "\n",
    "    for line in f.readlines():\n",
    "        if not line in [u'\\n', u'\\r\\n']:\n",
    "            token, tag = line.split(' ')\n",
    "            if last_token.endswith('.') and not last_token in ['e.g.', 'i.e.']:\n",
    "                if token[0].isupper():\n",
    "                    corpus.append(current_sent)\n",
    "                    current_sent=[]\n",
    "            current_sent.append((token, tag.strip()))\n",
    "        else:\n",
    "            corpus.append(current_sent)\n",
    "            current_sent=[]\n",
    "    corpus.append(current_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Positive Preditions: ', 18457, ' Number of True Labels: ', 19649)\n",
      "Num_Correct:  801\n",
      "Num_Pos_Predictions:  18457\n",
      "Precision:  0.0433981687165\n",
      "Accuracy:  0.682696801451\n",
      "F1:  0.0420406235239\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pos\n",
    "import nltk\n",
    "\n",
    "y_pred = []\n",
    "y_expected = []\n",
    "\n",
    "hmm = pos.HMM()\n",
    "for sentence in corpus:\n",
    "    hmm.update_counts(sentence)\n",
    "hmm.compute_logprobs()\n",
    "def pretty_print_fb(sentence):\n",
    "    #print sentence\n",
    "    #print hmm.forward_backward(sentence.split())\n",
    "    return hmm.forward_backward(sentence.split())\n",
    "\n",
    "#for x in xrange(1):\n",
    "for x in xrange(len(corpus)):\n",
    "    \n",
    "    #print(\"Predicted:\")\n",
    "    #y_pred = pretty_print_fb(' '.join([i for i,j in corpus[x]]))\n",
    "    y_pred_result = pretty_print_fb(' '.join([i for i,j in corpus[x]]))\n",
    "    y_pred = np.append(y_pred, [y_pred_result])\n",
    "    \n",
    "    #print(\"Expected:\")\n",
    "    #y_expected = [j for i, j in corpus[x]]\n",
    "    y_expected_result = [j for i, j in corpus[x]]\n",
    "    y_expected = np.append(y_expected, [y_expected_result])\n",
    "\n",
    "num_pos_predictions = len([i for i in y_pred if i != \"O\"])\n",
    "num_pos_predictions\n",
    "num_true_labels = len([i for i in y_expected if i != \"O\"])\n",
    "num_true_labels\n",
    "\n",
    "print(\"Positive Preditions: \", num_pos_predictions, \" Number of True Labels: \", num_true_labels)\n",
    "\n",
    "num_correct = num_correct_all = 0\n",
    "for (a,b) in zip(y_pred, y_expected):\n",
    "    if (a == b):\n",
    "        num_correct_all += 1\n",
    "        if (a != \"O\"):\n",
    "            num_correct += 1\n",
    "\n",
    "precision = num_correct * 1.0 / num_pos_predictions\n",
    "recall = num_correct * 1.0 / num_true_labels\n",
    "accuracy = num_correct_all * 1.0 / len(y_pred)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print \"Num_Correct: \", num_correct\n",
    "print \"Num_Pos_Predictions: \", num_pos_predictions\n",
    "print \"Precision: \", precision\n",
    "print \"Accuracy: \", accuracy\n",
    "print \"F1: \", f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'B-Material' u'O' u'B-Material' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'B-Process' u'I-Process' u'I-Process' u'O' u'O' u'B-Process'\n",
      "  u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'B-Task' u'I-Task' u'I-Task' u'O' u'B-Material' u'O' u'O' u'B-Process'\n",
      "  u'I-Process' u'I-Process' u'I-Process' u'O' u'B-Process' u'I-Process'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'B-Process' u'I-Process' u'I-Process' u'I-Process'\n",
      "  u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Material' u'B-Process'\n",
      "  u'I-Process' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'O' u'O' u'O'\n",
      "  u'O' u'B-Process' u'I-Process' u'I-Process' u'I-Process' u'I-Process'\n",
      "  u'I-Process' u'I-Process' u'I-Process' u'I-Process' u'I-Process'\n",
      "  u'I-Process' u'I-Process' u'I-Process' u'I-Process' u'I-Process' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Material'\n",
      "  u'I-Material' u'B-Task' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'B-Material' u'I-Material' u'I-Material'\n",
      "  u'B-Process' u'I-Process' u'I-Process' u'B-Material' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Material' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Material'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'B-Material' u'B-Material' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Process'\n",
      "  u'I-Process' u'B-Material' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'B-Material' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      "  u'O' u'O' u'O' u'O' u'O']]\n",
      "[u'B-Material' u'O' u'B-Material' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'B-Process' u'I-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Task' u'I-Task' u'I-Task' u'O' u'O'\n",
      " u'O' u'O' u'B-Process' u'I-Process' u'I-Process' u'I-Process' u'O'\n",
      " u'B-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'B-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process'\n",
      " u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'I-Process' u'I-Process'\n",
      " u'I-Process' u'I-Process' u'O' u'O' u'I-Process' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'I-Process' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'B-Material' u'I-Material' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'I-Task' u'I-Task' u'O' u'O' u'O'\n",
      " u'B-Process' u'I-Process' u'I-Process' u'I-Process' u'O' u'B-Process'\n",
      " u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'B-Process' u'I-Process' u'I-Process' u'I-Process'\n",
      " u'I-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'B-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process'\n",
      " u'O' u'O' u'B-Material' u'I-Material' u'I-Material' u'B-Process'\n",
      " u'I-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'B-Process' u'I-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'I-Task' u'I-Task' u'O' u'O'\n",
      " u'O' u'B-Process' u'I-Process' u'I-Process' u'I-Process' u'O' u'B-Process'\n",
      " u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'I-Process'\n",
      " u'I-Process' u'I-Process' u'I-Process' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'I-Process'\n",
      " u'I-Process' u'I-Process' u'I-Process' u'I-Process' u'O' u'O' u'I-Process'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'I-Process' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'B-Process' u'I-Process' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O' u'O'\n",
      " u'B-Process' u'I-Process' u'O' u'O' u'B-Material' u'I-Material' u'O']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_expected_array = np.asarray(y_expected)\n",
    "print y_expected_array.shape\n",
    "y_pred_array = np.asarray(y_pred)\n",
    "print y_pred_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, let's take a few moments to inspect the format of the training data.  The Treebank Reader object has a `tagged_sents()` function that returns an list of sentences.  Each sentence consists of a list of (word, part of speech) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3914 sentences in the corpus.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "import unittest\n",
    "\n",
    "import pos\n",
    "import pos_test\n",
    "from nltk.corpus.reader.tagged import TaggedCorpusReader\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import tokenize\n",
    "\n",
    "\n",
    "#def ie_preprocess(document):\n",
    "#    sentences = nltk.sent_tokenize(\"test.txt\")\n",
    "#    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "#    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "#    return sentences\n",
    "\n",
    "#doc = 'test.txt'\n",
    "#ie_preprocess(doc)\n",
    "    \n",
    "#f=open('train.txt','rU')\n",
    "#raw=f.read()\n",
    "#tokens = nltk.word_tokenize(raw)\n",
    "#text = nltk.Text(tokens)\n",
    "#corpus = text\n",
    "\n",
    "\n",
    "# Load the Penn Treebank Corpus which will serve as our training set.\n",
    "corpus = nltk.corpus.treebank\n",
    "\n",
    "#corpus = TaggedCorpusReader(\"\",\"test.txt\")\n",
    "\n",
    "#tagged = nltk.pos_tag(nltk.word_tokenize(corpus))\n",
    "#corpus.tagged_words(tagset='universal')\n",
    "#corpus.words()\n",
    "#corpus.tagged_words()[0:30]\n",
    "#corpus.sents()\n",
    "print 'There are %d sentences in the corpus.' % len(corpus.tagged_sents())\n",
    "#print 'The first sentence is:'\n",
    "#corpus.tagged_sents()[22]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#text = nltk.tokenize.word_tokenize(\"This system provides non-native learners with feedback on sentence stress errors.\")\n",
    "#nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a): HMM Parameterization\n",
    "\n",
    "![HMM diagram](HMM.png)\n",
    "\n",
    "Recall that a Hidden Markov Model models a sequence $[x_0, x_1, ..., x_n]$ as a Markov chain of _hidden_ states $[y_0, y_1, ..., y_n]$ and associated emissions $y_i \\to x_i$ at each position. Formally, we have three sets of parameters:\n",
    "\n",
    "1. An initial state probability $P(y_0)$ which determines the start state of the sequence.\n",
    "2. Transition probabilities $P(y_i\\ |\\ y_{i-1})$ from one state to the next.\n",
    "3. Emission probabilities $P(x_i\\ |\\ y_i)$ to generate an output at each timestep.\n",
    "\n",
    "For POS tagging, we treat the word (tokens) as the observed nodes $x_i$, and the part-of-speech tags as the hidden states $y_i$ associated with each token. At training time, since the data is fully tagged, we get to observe _both_ $x_i$ and $y_i$, and so we can train our model by maximum likelihood estimation.\n",
    "\n",
    "Recalling our n-gram models from Assignment 2, we can obtain the maximum likelihood parameters by simply counting. We'll use $t$ to denote a specific part-of-speech tag (from a tagset $T$), and $w$ to denote a specific word type (from a vocabulary $V$):\n",
    "\n",
    "1. Initial: $ P(y_0 = t) = \\frac{c(y_0 = t)}{\\sum_{t' \\in T} c(y_0 = t')} $\n",
    "2. Transition: $ P(y_i = t\\ |\\ y_{i-1} = t_1) = \\frac{c(t_1t)}{\\sum_{t' \\in T}c(t_1t')} $\n",
    "3. Emission: $ P(x_i = w\\ |\\ y_i = t) = \\frac{c(w\\ |\\ t)}{\\sum_{w' \\in V} c(w'\\ |\\ t)} $\n",
    "\n",
    "### Questions\n",
    "1.  Open pos.py and read estimate_probabilities and compute_logprobs.  This code should be very familiar as it's nearly identical to what you implemented in A2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_estimate_probabilities (pos_test.TestTagging) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pos)\n",
    "reload(pos_test)\n",
    "unittest.TextTestRunner(verbosity=2).run(\n",
    "    unittest.TestLoader().loadTestsFromName(\n",
    "        'TestTagging.test_estimate_probabilities', pos_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): Forward-Backward\n",
    "\n",
    "The forward-backward algorithm allows us to efficiently compute the most likely tag for any (or every) individual word. Formally, at each position $i$ we want to compute the marginal distribution $p(y_i\\ |\\ x_0, x_1, x_2, \\cdots, x_n) = p(y_i\\ |\\ x)$. Note that taking the most likely tag from this will not necessarily find the most likely _sequence_ of tags - we'll tackle that in part(c) with Viterbi.\n",
    "\n",
    "\n",
    "\n",
    "In [Live Session](https://docs.google.com/presentation/d/1lTqY-Pn6YUIkFmzn_k7ATzBA0k2a4gkdrMhibfV09_M/edit#slide=id.g1eb138b3b3_1_72), we found that by applying Bayes rule and decomposing (for dynamic programming speedup), $p(y_i\\ |\\ x)$ can be computed with the following equations. Let $n$ be the length of the sentence, and $w_i$ be the (fixed) token at position $i = 0, 1, ..., n$:\n",
    "\n",
    "- $ \\alpha(0, t) = p(t) \\times p(x_0\\ |\\ t) $\n",
    "- $ \\alpha(i, t) = p(w_i\\ |\\ t) \\times \\sum_{t'} p(t\\ |\\ t') \\times \\alpha(i - 1, t') $\n",
    "- $ \\beta(n, t) = 1 $\n",
    "- $ \\beta(i-1, t) = \\sum_{t'} p(w_{i}\\ |\\ t') \\times p(t'\\ |\\ t) \\times \\beta(i, t') $\n",
    "\n",
    "Intuitively,\n",
    "- **Forward beliefs** $\\alpha(i, t)$ represent the sum of all the paths that end in tag $t$ at position $i$.\n",
    "- **Backward beliefs** $\\beta(i, t)$ represent the sum of all the ways to continue on from tag $t$ at position $i$ through to position $n$.\n",
    "\n",
    "If we combine the forward beliefs (information from before position $i$) with the backward beliefs (information from beyond position $i$), we get the exact probability distribution:\n",
    "\n",
    "$$ p(y_i = t\\ |\\ x) = \\alpha(i,t) \\times \\beta(i,t) $$\n",
    "\n",
    "### Log-probabilities\n",
    "\n",
    "Note that we're multiplying a lot of probabilities together in the above equations. While each term is easy to represent as a float, we can quickly run into numerical underflow issues when multiplying together a large number of small values.  If your dataset is as small as this and the sentences you want to tag are short (i.e. not work with real data), you can sometimes get away without worrying about this.  Alternatively, you can petition Intel to improve precision of floating point numbers close to 0.\n",
    "\n",
    "To avoid this, we'll perform all our calculations in log space. This means that we start with the log-probabilities (as computed by `HMM.compute_logprobs()`), and replace multiplication with addition and addition with log-sum-exp, according to the identities:\n",
    "\n",
    "- $ \\log(a b) = \\log(a) + \\log(b) $\n",
    "- $ \\log(a + b) = \\log(e^{\\log(a)} + e^{\\log(b)}) = \\text{LogSumExp}(log(a), log(b)) $\n",
    "\n",
    "To implement the latter, we recommend using [`scipy.misc.logsumexp`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.misc.logsumexp.html), which is imported for you in the starter code.\n",
    "\n",
    "#### Cheat Sheet:  Summing probabilities\n",
    "\n",
    "Add probabilities together, $P(t_1) + P(t_2) + \\cdots + P(t_n)$.\n",
    "```python\n",
    "# \"Regular\" Probabilities\n",
    "sum_py = sum([p[t] for t in tags])\n",
    "# Log-probabilities\n",
    "log_sum_py = logsumexp([logp[t] for t in tags])\n",
    "```\n",
    "\n",
    "At the end of running this code,\n",
    "- `sum_py` $ = \\Sigma P(t_i)$\n",
    "- `log_sum_py` $ = log(\\Sigma P(t_i))$\n",
    "\n",
    "Normal and log-probabilities can always be converted into each other with a $e^x$ or $log(x)$, although you shouldn't need to do this explicitly in this assignment.\n",
    "\n",
    "_**Hint:**_ Your code in this part should look a lot like the math. In particular, `initial`, `transition`, and `emission` are defaultdicts that are already set up to return appropriate defaults ($\\log p(...) = \\log 0 = -\\infty$) for unseen tags - so you shouldn't need to check membership with `if` statements or `dict.get()`.\n",
    "\n",
    "### Questions\n",
    "1.  Implement alpha in pos.py\n",
    "2.  Implement beta in pos.py\n",
    "3.  Inspect forward_backward in pos.py.\n",
    "4.  What does forward/backward do at a high level?\n",
    "5.  How does this manifest in the equations above?\n",
    "6.  What can you say about the sequence of tags it produces?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "Question 4: Given a series of observed nodes (words) the forward-backward algorithm predicts the hidden nodes (parts of speech) by passing over the sentence twice - once in a forward direction (alpha) and again in the backward direction (beta). The forward-backward function in our code combines the probabilities to determine the best tag for each word.\n",
    "\n",
    "Question 5: Not quite sure I follow here - we are using dynamic program techniques to identify the POS tag of maximum likelihood by using the forward-backward algorithm. \n",
    "\n",
    "Question 6: The sequence of tags output are the maximum probabilities of the of individual tags (not the sequence of tags of maximum probablity) in the hidden layer of the HMM. This is a key distinction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_alpha (pos_test.TestTagging) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pos)\n",
    "reload(pos_test)\n",
    "unittest.TextTestRunner(verbosity=2).run(\n",
    "    unittest.TestLoader().loadTestsFromName(\n",
    "        'TestTagging.test_alpha', pos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_beta (pos_test.TestTagging) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pos)\n",
    "reload(pos_test)\n",
    "unittest.TextTestRunner(verbosity=2).run(\n",
    "    unittest.TestLoader().loadTestsFromName(\n",
    "        'TestTagging.test_beta', pos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward_backward (pos_test.TestTagging) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pos)\n",
    "reload(pos_test)\n",
    "unittest.TextTestRunner(verbosity=2).run(\n",
    "    unittest.TestLoader().loadTestsFromName(\n",
    "        'TestTagging.test_forward_backward', pos_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's give it a try!\n",
    "\n",
    "(Warning: if you decide to try some of your own - and you should! - you may find the limited vocabulary of the training set to be problematic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tagged_sents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5c1febba4415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_logprobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tagged_sents'"
     ]
    }
   ],
   "source": [
    "reload(pos)\n",
    "hmm = pos.HMM()\n",
    "for sentence in corpus.tagged_sents():\n",
    "    hmm.update_counts(sentence)\n",
    "hmm.compute_logprobs()\n",
    "def pretty_print_fb(sentence):\n",
    "    print sentence\n",
    "    print hmm.forward_backward(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_print_fb('Pierre will join the board .')\n",
    "pretty_print_fb('Pierre joined an organization .')\n",
    "pretty_print_fb('The old man .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c): Viterbi\n",
    "\n",
    "Viterbi finds the maximum likelihood sequence of assignments, rather than considering a single assignment at a time.  Its implementation is a small tweak on the $\\alpha$ of Forward Backward.  In particular, instead of trying to find the _sum_ of all the possible ways to make a part of speech in a particular position, we try to find the _best_ way. Formally, we have:\n",
    "\n",
    "- $\\delta(0, t) = p(t) \\times P(x_0\\ |\\ t)$\n",
    "- $\\delta(i, t) = p(x_i\\ |\\ t) \\times \\max_{t'} \\left[\\delta(i - 1, t') \\times p(t\\ |\\ t')\\right]$\n",
    "\n",
    "_**Hint:**_ As in part (b), your code should look quite a lot like the math above.\n",
    "\n",
    "### Questions:\n",
    "1.  Read the `viterbi` function at the bottom of pos.py.  It uses the delta table and backpointers to determine the most likely sequence of part of speech tags.\n",
    "2.  Implement the equations immediately above pos.py's `build_viterbi_delta`.\n",
    "3.  What does Viterbi do differently in its algorithm than forward of forward/backward?\n",
    "4.  What does this mean for the tags it produces?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "Q3: The primary difference is that Viterbi looks at the maximum likelihood of parts-of-speech tags for the entire sequence rather than each specific word. \n",
    "\n",
    "Q4: The tags produced may not be the outcome of maximum likelihood for each specific word, but it will be the most likely sequence of states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_build_viterbi_delta (pos_test.TestTagging) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pos)\n",
    "reload(pos_test)\n",
    "unittest.TextTestRunner(verbosity=2).run(\n",
    "    unittest.TestLoader().loadTestsFromName(\n",
    "        'TestTagging.test_build_viterbi_delta', pos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_viterbi_end_to_end (pos_test.TestTagging) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pos)\n",
    "reload(pos_test)\n",
    "unittest.TextTestRunner(verbosity=2).run(\n",
    "    unittest.TestLoader().loadTestsFromName(\n",
    "        'TestTagging.test_viterbi_end_to_end', pos_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's give it a try!\n",
    "\n",
    "(Warning: if you decide to try some of your own - and you should! - you may find the limited vocabulary of the training set to be problematic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /anaconda/envs/python2/lib/python2.7/site-packages\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3914/3914 [00:02<00:00, 1438.00it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = nltk.corpus.treebank\n",
    "# Uncomment below if you install the full Penn Treebank\n",
    "# corpus = nltk.corpus.ptb\n",
    "\n",
    "# Optional: set to true to get a nice progressbar during training.\n",
    "use_fancy_progressbar = True\n",
    "if use_fancy_progressbar:\n",
    "    !pip install tqdm\n",
    "    from tqdm import tqdm as ProgressBar\n",
    "else:\n",
    "    ProgressBar = lambda x: x\n",
    "\n",
    "reload(pos)\n",
    "hmm = pos.HMM()\n",
    "for sentence in ProgressBar(corpus.tagged_sents()):\n",
    "    hmm.update_counts(sentence)\n",
    "hmm.compute_logprobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre/NNP will/MD join/VB the/DT board/NN ./.\n",
      "Pierre/NNP joined/VBD an/DT organization/NN ./.\n",
      "The/DT old/JJ man/NN ./.\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_v(sentence):\n",
    "    tokens = sentence.split()\n",
    "    tags = hmm.viterbi(tokens)\n",
    "    print \" \".join(\"%s/%s\" % (w,t) for (w,t) in zip(tokens, tags))\n",
    "\n",
    "pretty_print_v('Pierre will join the board .')\n",
    "pretty_print_v('Pierre joined an organization .')\n",
    "pretty_print_v('The old man .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
